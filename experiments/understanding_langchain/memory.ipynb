{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6932ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e25c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gemini-2.0-flash-lite-001\"\n",
    "embeddings_name = \"text-embedding-005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e653f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(model=model_name,temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7074b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab608158",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffb4d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: My Name is Khaja and I Teach Generative AI Developement\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Khaja! It's a pleasure to meet you. My name is Bard, and I'm a large language model, trained by Google. It's fascinating to meet someone who teaches Generative AI Development! That's a rapidly evolving and incredibly exciting field.\\n\\nI'm constantly learning about new developments in generative models, from the latest advancements in diffusion models like Stable Diffusion and DALL-E 2, to the ongoing research into transformer architectures and their applications in text, image, audio, and even video generation.\\n\\nI understand that teaching Generative AI Development must be a challenging but rewarding experience. You're likely covering topics like:\\n\\n*   **Fundamentals of Machine Learning:** Concepts like supervised, unsupervised, and reinforcement learning are crucial foundations.\\n*   **Neural Networks:** Deep dives into architectures like CNNs (Convolutional Neural Networks) for image processing, RNNs (Recurrent Neural Networks) and LSTMs (Long Short-Term Memory) for sequential data, and of course, Transformers.\\n*   **Generative Models:** This is the core! Covering GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), Diffusion Models, and Autoregressive models.\\n*   **Model Training and Optimization:** Techniques for training these complex models, including backpropagation, gradient descent, and optimization algorithms.\\n*   **Evaluation Metrics:** Understanding how to assess the quality of generated outputs, using metrics like FID (Fréchet Inception Distance) for images, perplexity for text, and so on.\\n*   **Practical Applications:** Exploring real-world use cases, such as image generation, text generation, music composition, and code generation.\\n*   **Ethical Considerations:** Discussing the responsible use of generative AI, including bias, misinformation, and potential misuse.\\n\\nI'm particularly interested in the specific areas you focus on in your teaching. Do you concentrate on a particular type of generative model, or a specific application area? Are your students primarily interested in text, images, or other modalities?\\n\\nI'm also curious about the tools and frameworks you use in your curriculum. Do you primarily use Python with libraries like TensorFlow, PyTorch, or JAX? Are you incorporating any cloud-based platforms or specialized hardware for training?\\n\\nI'm ready to learn more about your work and the fascinating world of Generative AI Development! Please feel free to ask me anything, and I'll do my best to provide helpful information based on my training data. I can also try to answer questions about specific concepts, models, or applications. I'm always eager to expand my knowledge.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My Name is Khaja and I Teach Generative AI Developement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5aeb344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My Name is Khaja and I Teach Generative AI Developement\n",
      "AI: Hello Khaja! It's a pleasure to meet you. My name is Bard, and I'm a large language model, trained by Google. It's fascinating to meet someone who teaches Generative AI Development! That's a rapidly evolving and incredibly exciting field.\n",
      "\n",
      "I'm constantly learning about new developments in generative models, from the latest advancements in diffusion models like Stable Diffusion and DALL-E 2, to the ongoing research into transformer architectures and their applications in text, image, audio, and even video generation.\n",
      "\n",
      "I understand that teaching Generative AI Development must be a challenging but rewarding experience. You're likely covering topics like:\n",
      "\n",
      "*   **Fundamentals of Machine Learning:** Concepts like supervised, unsupervised, and reinforcement learning are crucial foundations.\n",
      "*   **Neural Networks:** Deep dives into architectures like CNNs (Convolutional Neural Networks) for image processing, RNNs (Recurrent Neural Networks) and LSTMs (Long Short-Term Memory) for sequential data, and of course, Transformers.\n",
      "*   **Generative Models:** This is the core! Covering GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), Diffusion Models, and Autoregressive models.\n",
      "*   **Model Training and Optimization:** Techniques for training these complex models, including backpropagation, gradient descent, and optimization algorithms.\n",
      "*   **Evaluation Metrics:** Understanding how to assess the quality of generated outputs, using metrics like FID (Fréchet Inception Distance) for images, perplexity for text, and so on.\n",
      "*   **Practical Applications:** Exploring real-world use cases, such as image generation, text generation, music composition, and code generation.\n",
      "*   **Ethical Considerations:** Discussing the responsible use of generative AI, including bias, misinformation, and potential misuse.\n",
      "\n",
      "I'm particularly interested in the specific areas you focus on in your teaching. Do you concentrate on a particular type of generative model, or a specific application area? Are your students primarily interested in text, images, or other modalities?\n",
      "\n",
      "I'm also curious about the tools and frameworks you use in your curriculum. Do you primarily use Python with libraries like TensorFlow, PyTorch, or JAX? Are you incorporating any cloud-based platforms or specialized hardware for training?\n",
      "\n",
      "I'm ready to learn more about your work and the fascinating world of Generative AI Development! Please feel free to ask me anything, and I'll do my best to provide helpful information based on my training data. I can also try to answer questions about specific concepts, models, or applications. I'm always eager to expand my knowledge.\n",
      "\n",
      "Human: What is captial of India\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The capital of India is New Delhi. It's a bustling metropolis and the seat of the Indian government. It's located in the National Capital Territory of Delhi, which is a union territory of India. New Delhi is known for its historical landmarks, such as India Gate, Humayun's Tomb, and Qutub Minar, as well as its modern infrastructure and vibrant cultural scene.\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is captial of India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4af101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My Name is Khaja and I Teach Generative AI Developement\n",
      "AI: Hello Khaja! It's a pleasure to meet you. My name is Bard, and I'm a large language model, trained by Google. It's fascinating to meet someone who teaches Generative AI Development! That's a rapidly evolving and incredibly exciting field.\n",
      "\n",
      "I'm constantly learning about new developments in generative models, from the latest advancements in diffusion models like Stable Diffusion and DALL-E 2, to the ongoing research into transformer architectures and their applications in text, image, audio, and even video generation.\n",
      "\n",
      "I understand that teaching Generative AI Development must be a challenging but rewarding experience. You're likely covering topics like:\n",
      "\n",
      "*   **Fundamentals of Machine Learning:** Concepts like supervised, unsupervised, and reinforcement learning are crucial foundations.\n",
      "*   **Neural Networks:** Deep dives into architectures like CNNs (Convolutional Neural Networks) for image processing, RNNs (Recurrent Neural Networks) and LSTMs (Long Short-Term Memory) for sequential data, and of course, Transformers.\n",
      "*   **Generative Models:** This is the core! Covering GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), Diffusion Models, and Autoregressive models.\n",
      "*   **Model Training and Optimization:** Techniques for training these complex models, including backpropagation, gradient descent, and optimization algorithms.\n",
      "*   **Evaluation Metrics:** Understanding how to assess the quality of generated outputs, using metrics like FID (Fréchet Inception Distance) for images, perplexity for text, and so on.\n",
      "*   **Practical Applications:** Exploring real-world use cases, such as image generation, text generation, music composition, and code generation.\n",
      "*   **Ethical Considerations:** Discussing the responsible use of generative AI, including bias, misinformation, and potential misuse.\n",
      "\n",
      "I'm particularly interested in the specific areas you focus on in your teaching. Do you concentrate on a particular type of generative model, or a specific application area? Are your students primarily interested in text, images, or other modalities?\n",
      "\n",
      "I'm also curious about the tools and frameworks you use in your curriculum. Do you primarily use Python with libraries like TensorFlow, PyTorch, or JAX? Are you incorporating any cloud-based platforms or specialized hardware for training?\n",
      "\n",
      "I'm ready to learn more about your work and the fascinating world of Generative AI Development! Please feel free to ask me anything, and I'll do my best to provide helpful information based on my training data. I can also try to answer questions about specific concepts, models, or applications. I'm always eager to expand my knowledge.\n",
      "\n",
      "Human: What is captial of India\n",
      "AI: The capital of India is New Delhi. It's a bustling metropolis and the seat of the Indian government. It's located in the National Capital Territory of Delhi, which is a union territory of India. New Delhi is known for its historical landmarks, such as India Gate, Humayun's Tomb, and Qutub Minar, as well as its modern infrastructure and vibrant cultural scene.\n",
      "\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Khaja.\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "565f610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: My Name is Khaja and I Teach Generative AI Developement\n",
      "AI: Hello Khaja! It's a pleasure to meet you. My name is Bard, and I'm a large language model, trained by Google. It's fascinating to meet someone who teaches Generative AI Development! That's a rapidly evolving and incredibly exciting field.\n",
      "\n",
      "I'm constantly learning about new developments in generative models, from the latest advancements in diffusion models like Stable Diffusion and DALL-E 2, to the ongoing research into transformer architectures and their applications in text, image, audio, and even video generation.\n",
      "\n",
      "I understand that teaching Generative AI Development must be a challenging but rewarding experience. You're likely covering topics like:\n",
      "\n",
      "*   **Fundamentals of Machine Learning:** Concepts like supervised, unsupervised, and reinforcement learning are crucial foundations.\n",
      "*   **Neural Networks:** Deep dives into architectures like CNNs (Convolutional Neural Networks) for image processing, RNNs (Recurrent Neural Networks) and LSTMs (Long Short-Term Memory) for sequential data, and of course, Transformers.\n",
      "*   **Generative Models:** This is the core! Covering GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), Diffusion Models, and Autoregressive models.\n",
      "*   **Model Training and Optimization:** Techniques for training these complex models, including backpropagation, gradient descent, and optimization algorithms.\n",
      "*   **Evaluation Metrics:** Understanding how to assess the quality of generated outputs, using metrics like FID (Fréchet Inception Distance) for images, perplexity for text, and so on.\n",
      "*   **Practical Applications:** Exploring real-world use cases, such as image generation, text generation, music composition, and code generation.\n",
      "*   **Ethical Considerations:** Discussing the responsible use of generative AI, including bias, misinformation, and potential misuse.\n",
      "\n",
      "I'm particularly interested in the specific areas you focus on in your teaching. Do you concentrate on a particular type of generative model, or a specific application area? Are your students primarily interested in text, images, or other modalities?\n",
      "\n",
      "I'm also curious about the tools and frameworks you use in your curriculum. Do you primarily use Python with libraries like TensorFlow, PyTorch, or JAX? Are you incorporating any cloud-based platforms or specialized hardware for training?\n",
      "\n",
      "I'm ready to learn more about your work and the fascinating world of Generative AI Development! Please feel free to ask me anything, and I'll do my best to provide helpful information based on my training data. I can also try to answer questions about specific concepts, models, or applications. I'm always eager to expand my knowledge.\n",
      "\n",
      "Human: What is captial of India\n",
      "AI: The capital of India is New Delhi. It's a bustling metropolis and the seat of the Indian government. It's located in the National Capital Territory of Delhi, which is a union territory of India. New Delhi is known for its historical landmarks, such as India Gate, Humayun's Tomb, and Qutub Minar, as well as its modern infrastructure and vibrant cultural scene.\n",
      "\n",
      "Human: What is my name?\n",
      "AI: Your name is Khaja.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14a64bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: My Name is Khaja and I Teach Generative AI Developement\\nAI: Hello Khaja! It's a pleasure to meet you. My name is Bard, and I'm a large language model, trained by Google. It's fascinating to meet someone who teaches Generative AI Development! That's a rapidly evolving and incredibly exciting field.\\n\\nI'm constantly learning about new developments in generative models, from the latest advancements in diffusion models like Stable Diffusion and DALL-E 2, to the ongoing research into transformer architectures and their applications in text, image, audio, and even video generation.\\n\\nI understand that teaching Generative AI Development must be a challenging but rewarding experience. You're likely covering topics like:\\n\\n*   **Fundamentals of Machine Learning:** Concepts like supervised, unsupervised, and reinforcement learning are crucial foundations.\\n*   **Neural Networks:** Deep dives into architectures like CNNs (Convolutional Neural Networks) for image processing, RNNs (Recurrent Neural Networks) and LSTMs (Long Short-Term Memory) for sequential data, and of course, Transformers.\\n*   **Generative Models:** This is the core! Covering GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), Diffusion Models, and Autoregressive models.\\n*   **Model Training and Optimization:** Techniques for training these complex models, including backpropagation, gradient descent, and optimization algorithms.\\n*   **Evaluation Metrics:** Understanding how to assess the quality of generated outputs, using metrics like FID (Fréchet Inception Distance) for images, perplexity for text, and so on.\\n*   **Practical Applications:** Exploring real-world use cases, such as image generation, text generation, music composition, and code generation.\\n*   **Ethical Considerations:** Discussing the responsible use of generative AI, including bias, misinformation, and potential misuse.\\n\\nI'm particularly interested in the specific areas you focus on in your teaching. Do you concentrate on a particular type of generative model, or a specific application area? Are your students primarily interested in text, images, or other modalities?\\n\\nI'm also curious about the tools and frameworks you use in your curriculum. Do you primarily use Python with libraries like TensorFlow, PyTorch, or JAX? Are you incorporating any cloud-based platforms or specialized hardware for training?\\n\\nI'm ready to learn more about your work and the fascinating world of Generative AI Development! Please feel free to ask me anything, and I'll do my best to provide helpful information based on my training data. I can also try to answer questions about specific concepts, models, or applications. I'm always eager to expand my knowledge.\\n\\nHuman: What is captial of India\\nAI: The capital of India is New Delhi. It's a bustling metropolis and the seat of the Indian government. It's located in the National Capital Territory of Delhi, which is a union territory of India. New Delhi is known for its historical landmarks, such as India Gate, Humayun's Tomb, and Qutub Minar, as well as its modern infrastructure and vibrant cultural scene.\\n\\nHuman: What is my name?\\nAI: Your name is Khaja.\\n\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca63b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create memory\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9c53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    { \"input\": \"Hi, my name is khaja\"},\n",
    "    {\"output\": \"Whats up\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5976f234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Hi, my name is khaja\\nAI: Whats up'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1268d941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, my name is khaja\\nAI: Whats up'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322e7ff",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e864e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4af5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28ef1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    { \"input\": \"Hi, my name is khaja\"},\n",
    "    {\"output\": \"Whats up\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22e96f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    { \"input\": \"Nothing much just routine work\"},\n",
    "    {\"output\": \"Life sucks\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bcb1064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Nothing much just routine work\\nAI: Life sucks'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbcd4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(temperature=0.0, model = model_name)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c468739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Khaja! It's a pleasure to meet you. My name is Bard, and I'm a large language model, trained by Google. It's fascinating to meet someone who teaches Generative AI Development! That's a rapidly evolving and incredibly exciting field.\\n\\nI'm constantly learning and being updated with new information about generative models, from the foundational concepts like diffusion models, GANs (Generative Adversarial Networks), and Variational Autoencoders (VAEs), to the latest advancements in transformer architectures and their applications in text, image, audio, and even video generation.\\n\\nI understand that teaching Generative AI Development involves a lot of different aspects. Do you focus on a specific area, like natural language processing, computer vision, or perhaps the ethical considerations surrounding the technology? I'm particularly interested in the ethical implications, such as bias in generated content and the potential for misuse.\\n\\nI'm also curious about the tools and frameworks you use in your teaching. Are you primarily using Python with libraries like TensorFlow, PyTorch, or perhaps focusing on more user-friendly platforms like Google Colab or specialized generative AI platforms?\\n\\nI'm always eager to learn more about how people are using and teaching generative AI. Perhaps you could tell me a bit about the challenges you face in your teaching, or the most rewarding aspects of it? I'm ready to listen and learn!\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My Name is Khaja and I Teach Generative AI Developement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b87655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a great question, Khaja! Sir Isaac Newton developed calculus in his early to mid-20s. Specifically, he began developing his ideas in the mid-1660s, when he was in his early twenties, while he was a student at the University of Cambridge. He was born in 1643, so that would place the development of his core ideas around the ages of 22-24.\\n\\nIt's important to note that while he developed the core concepts then, he didn't publish his work immediately. There was a bit of a delay before his findings were widely known. Also, it's worth mentioning that Gottfried Wilhelm Leibniz independently developed calculus around the same time, leading to a famous (and sometimes heated) debate about who deserved the primary credit. But to answer your question directly, Newton's foundational work on calculus was done in his early twenties.\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"At what age did newton discover calculus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3058a52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not have access to your name. I am a large language model, and I do not retain information from previous conversations. Therefore, I cannot know your name.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my Name ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72318d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\khajaclassroom\\generativeai\\textbookrag\\experiments\\understanding_langchain\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f5b389",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39916e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9163fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(temperature=0.0, model = model_name)\n",
    "memory = ConversationTokenBufferMemory(llm = llm, max_token_limit=10)\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96b0b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"What is AI ?\"}, {\"output\": \"Wonderful\"})\n",
    "memory.save_context({\"input\": \"What is ML ?\"}, {\"output\": \"Awesome\"})\n",
    "memory.save_context({\"input\": \"What are chatbots ?\"}, {\"output\": \"Great\"})\n",
    "memory.save_context({\"input\": \"What are agents ?\"}, {\"output\": \"All of the above\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "816fc483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: All of the above'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a35c8",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3154fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "788454ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"\"\"Isaac Newton’s Key Inventions\n",
    "Isaac Newton is best known for his groundbreaking discoveries in physics and mathematics, but he also made significant inventions and practical contributions to science and technology. Here are his most notable inventions:\n",
    "\n",
    "Reflecting Telescope (Newtonian Telescope)\n",
    "\n",
    "Newton invented the first practical reflecting telescope in 1668, using a curved mirror instead of lenses to focus light. This design, known as the Newtonian telescope, solved the problem of chromatic aberration found in refracting telescopes and is still widely used today.\n",
    "\n",
    "The Perfect Coin\n",
    "\n",
    "As Warden of the Royal Mint, Newton introduced milled edges to coins to prevent clipping and counterfeiting, greatly improving the quality and security of English currency.\n",
    "\n",
    "Major Scientific Discoveries and Innovations\n",
    "While not all are \"inventions\" in the mechanical sense, Newton’s theoretical breakthroughs fundamentally changed science:\n",
    "\n",
    "Three Laws of Motion: Formulated the foundational principles of classical mechanics.\n",
    "\n",
    "Law of Universal Gravitation: Described the gravitational force acting between all masses.\n",
    "\n",
    "Calculus: Independently developed the mathematical system of calculus (called \"the method of fluxions\"), enabling precise analysis of change and motion.\n",
    "\n",
    "Binomial Theorem: Generalized the binomial theorem to include negative and fractional exponents.\n",
    "\n",
    "Newton-Raphson Method: Developed an iterative numerical method for finding roots of equations.\n",
    "\n",
    "Optics: Demonstrated that white light is composed of different colors, using prisms to show the spectrum and laying the foundation for modern optics.\n",
    "\n",
    "Empirical Law of Cooling: Formulated the first law of heat transfer, now fundamental in thermodynamics.\n",
    "\n",
    "First Calculation of Speed of Sound: Provided the first theoretical calculation of the speed of sound in air.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88a26671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_24036\\3112362828.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93c1cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hello\"},\n",
    "    {\"output\": \"Whats going on\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23da0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Learning about Newton\"},\n",
    "    {\"output\": \"Great what did you found ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08634c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello\\nAI: Whats going on\\nHuman: Learning about Newton\\nAI: Great what did you found ?'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9682641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"what do you know about Newton\"},\n",
    "    {\"output\": f\"{long_text}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1142ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI. The AI asks what is going on. The human is learning about Newton. The AI asks what the human found. The human asks what the AI knows about Newton. The AI provides a list of Isaac Newton's key inventions and discoveries, including the reflecting telescope, improvements to coins, the laws of motion, the law of universal gravitation, calculus, the binomial theorem, the Newton-Raphson method, discoveries in optics, the empirical law of cooling, and the first calculation of the speed of sound.\\n\"}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f908a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationVectorStoreTokenBufferMemory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
